tau_block ~ dunif(0, 1)
tau_id ~ dunif(0, 1)
sigma ~ dunif(0, 1) # prior for variance components based on Gelman (2006);
# reduced model
for(i in 1:n) {
y[i] ~ dnorm(
betaTrt[trt[i]] +
betaYear[year[i]] +
# u_yi[yi[i]] +
# u_block[block[i]] +
# u_id[id[i]],
sd = sigma
constants <- list(
n = nrow(tss_df),
#nyi = length(unique(tss_df$yi)),
#nblock = length(unique(tss_df$block)),
#nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
#yi = tss_df$yi,
#id = tss_df$id,
year = tss_df$year,
#block = tss_df$block
)
# Step 1: Build the model
code <- nimbleCode({
# This is where we define parameters and set priors.
# DO NOT SET PRIORS USING YOUR DATA TO INFORM THEM
# Fixed effects
# consider dropping this beta_0 since it offers no additional functionality;
# this would mean the model intercept would default to CT, likely.
# beta0 ~ dnorm(0, sd = 0.8)
# Looping over the elements of betaTrt and betaYear
for(k in 1:3) {
betaTrt[k] ~ dnorm(0, sd = 1)
}
for(k in 1:maxYear) {
betaYear[k] ~ dnorm(0, sd = 1)
}
# Random effects
# Gelman (2006) recommends the uniform prior on the sd scale not the precision scale for random effects:
# E.g., u_yi[j] ~ dnorm(0, sd = tau_yi) NOT u_yi[j] ~ dnorm(0, tau_yi)
# yi
for(j in 1:nyi) {
u_yi[j] ~ dnorm(0, sd = tau_yi)
}
# block
for(j in 1:nblock) {
u_block[j] ~ dnorm(0, sd = tau_block)
}
# id
for(j in 1:nid) {
u_id[j] ~ dnorm(0, sd = tau_id)
}
tau_yi ~ dunif(0, 1)
tau_block ~ dunif(0, 1)
tau_id ~ dunif(0, 1)
sigma ~ dunif(0, 1) # prior for variance components based on Gelman (2006);
# reduced model
for(i in 1:n) {
y[i] ~ dnorm(
betaTrt[trt[i]] +
betaYear[year[i]] +
# u_yi[yi[i]] +
# u_block[block[i]] +
# u_id[id[i]],
,sd = sigma
# Step 1: Build the model
code <- nimbleCode({
# This is where we define parameters and set priors.
# DO NOT SET PRIORS USING YOUR DATA TO INFORM THEM
# Fixed effects
# consider dropping this beta_0 since it offers no additional functionality;
# this would mean the model intercept would default to CT, likely.
# beta0 ~ dnorm(0, sd = 0.8)
# Looping over the elements of betaTrt and betaYear
for(k in 1:3) {
betaTrt[k] ~ dnorm(0, sd = 1)
}
for(k in 1:maxYear) {
betaYear[k] ~ dnorm(0, sd = 1)
}
# Random effects
# Gelman (2006) recommends the uniform prior on the sd scale not the precision scale for random effects:
# E.g., u_yi[j] ~ dnorm(0, sd = tau_yi) NOT u_yi[j] ~ dnorm(0, tau_yi)
# yi
for(j in 1:nyi) {
u_yi[j] ~ dnorm(0, sd = tau_yi)
}
# block
for(j in 1:nblock) {
u_block[j] ~ dnorm(0, sd = tau_block)
}
# id
for(j in 1:nid) {
u_id[j] ~ dnorm(0, sd = tau_id)
}
tau_yi ~ dunif(0, 1)
tau_block ~ dunif(0, 1)
tau_id ~ dunif(0, 1)
sigma ~ dunif(0, 1) # prior for variance components based on Gelman (2006);
# reduced model
for(i in 1:n) {
y[i] ~ dnorm(
betaTrt[trt[i]] +
betaYear[year[i]],# +
# u_yi[yi[i]] +
# u_block[block[i]] +
# u_id[id[i]],
sd = sigma
)
}
# Other models to consider, just commented out for reference:
# 'full model'
# for(i in 1:n) {
#   tss[i] ~ dnorm(beta0 + betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
# 'no-intercept/B0 model'
# for(i in 1:n) {
#   y[i] ~ dnorm(betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
})
constants <- list(
n = nrow(tss_df),
#nyi = length(unique(tss_df$yi)),
#nblock = length(unique(tss_df$block)),
#nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
#yi = tss_df$yi,
#id = tss_df$id,
year = tss_df$year,
#block = tss_df$block
)
constants <- list(
n = nrow(tss_df),
#nyi = length(unique(tss_df$yi)),
#nblock = length(unique(tss_df$block)),
#nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
#yi = tss_df$yi,
#id = tss_df$id,
year = tss_df$year#,
#block = tss_df$block
)
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6], # using std. dev. of analyte_ctr from sv tibble
#tau_yi = 1,
#tau_block = 1,
#tau_id = 1,
#u_yi = rep(0, constants$nyi),
#u_block = rep(0, constants$nblock),
#u_id = rep(0, constants$nid)
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6]#, # using std. dev. of analyte_ctr from sv tibble
#tau_yi = 1,
#tau_block = 1,
#tau_id = 1,
#u_yi = rep(0, constants$nyi),
#u_block = rep(0, constants$nblock),
#u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
constants <- list(
n = nrow(tss_df),
#nyi = length(unique(tss_df$yi)),
#nblock = length(unique(tss_df$block)),
#nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
#yi = tss_df$yi,
#id = tss_df$id,
year = tss_df$year#,
#block = tss_df$block
)
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6]#, # using std. dev. of analyte_ctr from sv tibble
#tau_yi = 1,
#tau_block = 1,
#tau_id = 1,
#u_yi = rep(0, constants$nyi),
#u_block = rep(0, constants$nblock),
#u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
constants <- list(
n = nrow(tss_df),
nyi = length(unique(tss_df$yi)),
nblock = length(unique(tss_df$block)),
nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
yi = tss_df$yi,
id = tss_df$id,
year = tss_df$year#,
block = tss_df$block
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6]#, # using std. dev. of analyte_ctr from sv tibble
#tau_yi = 1,
#tau_block = 1,
#tau_id = 1,
#u_yi = rep(0, constants$nyi),
#u_block = rep(0, constants$nblock),
#u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
# Step 2: Build the MCMC
TSSmcmc <- buildMCMC(TSSmodel, enableWAIC = TRUE)
TSSmcmc
TSSmcmc$model
TSSmcmc$monitors
constants <- list(
n = nrow(tss_df),
nyi = length(unique(tss_df$yi)),
nblock = length(unique(tss_df$block)),
nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
yi = tss_df$yi,
id = tss_df$id,
year = tss_df$year,
block = tss_df$block
)
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6]#, # using std. dev. of analyte_ctr from sv tibble
#tau_yi = 1,
#tau_block = 1,
#tau_id = 1,
#u_yi = rep(0, constants$nyi),
#u_block = rep(0, constants$nblock),
#u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
# Step 2: Build the MCMC
TSSmcmc <- buildMCMC(TSSmodel, enableWAIC = TRUE)
# Step 3: Compile the model and MCMC
cTSSmodel <- compileNimble(TSSmodel,showCompilerOutput = TRUE)
cTSSmcmc <- compileNimble(TSSmcmc, project = TSSmodel)
# Step 4: Run the MCMC
time_baseline <- system.time(TSSresults <- runMCMC(cTSSmcmc,
niter=11000,
nburnin=1000, #1000
WAIC=TRUE,
nchains=1)
)
cat("Sampling time: ", time_baseline[3], "seconds.\n")
# Step 5: Extract the samples and WAIC
# Samples
samples <- TSSresults$samples
colnames(samples)
summary(samples)
# Watanabe-Akaike Information Criterion (WAIC): captures model fit
# Log Pointwise Predictive Density (LPPD): captures model complexity
# effective number of parameters in the model (pWAIC): balances previous two
# The relationship: WAIC=−2×lppd+2×pWAIC
WAIC <- TSSresults$WAIC
WAIC
# Step 1: Build the model
code <- nimbleCode({
# This is where we define parameters and set priors.
# DO NOT SET PRIORS USING YOUR DATA TO INFORM THEM
# Fixed effects
# consider dropping this beta_0 since it offers no additional functionality;
# this would mean the model intercept would default to CT, likely.
# beta0 ~ dnorm(0, sd = 0.8)
# Looping over the elements of betaTrt and betaYear
for(k in 1:3) {
betaTrt[k] ~ dnorm(0, sd = 1)
}
for(k in 1:maxYear) {
betaYear[k] ~ dnorm(0, sd = 1)
}
# Random effects
# Gelman (2006) recommends the uniform prior on the sd scale not the precision scale for random effects:
# E.g., u_yi[j] ~ dnorm(0, sd = tau_yi) NOT u_yi[j] ~ dnorm(0, tau_yi)
# yi
for(j in 1:nyi) {
u_yi[j] ~ dnorm(0, sd = tau_yi)
}
# block
for(j in 1:nblock) {
u_block[j] ~ dnorm(0, sd = tau_block)
}
# id
for(j in 1:nid) {
u_id[j] ~ dnorm(0, sd = tau_id)
}
tau_yi ~ dunif(0, 1)
tau_block ~ dunif(0, 1)
tau_id ~ dunif(0, 1)
sigma ~ dunif(0, 1) # prior for variance components based on Gelman (2006);
# reduced model
for(i in 1:n) {
y[i] ~ dnorm(
betaTrt[trt[i]] +
betaYear[year[i]],# +
u_yi[yi[i]] +
u_block[block[i]] +
u_id[id[i]],
sd = sigma
)
}
# Other models to consider, just commented out for reference:
# 'full model'
# for(i in 1:n) {
#   tss[i] ~ dnorm(beta0 + betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
# 'no-intercept/B0 model'
# for(i in 1:n) {
#   y[i] ~ dnorm(betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
})
constants <- list(
n = nrow(tss_df),
nyi = length(unique(tss_df$yi)),
nblock = length(unique(tss_df$block)),
nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
# Converting factors to numeric below for MCMC
trt = tss_df$trt,
yi = tss_df$yi,
id = tss_df$id,
year = tss_df$year,
block = tss_df$block
)
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6], # using std. dev. of analyte_ctr from sv tibble
tau_yi = 1,
tau_block = 1,
tau_id = 1,
u_yi = rep(0, constants$nyi),
u_block = rep(0, constants$nblock),
u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
# Step 1: Build the model
code <- nimbleCode({
# This is where we define parameters and set priors.
# DO NOT SET PRIORS USING YOUR DATA TO INFORM THEM
# Fixed effects
# consider dropping this beta_0 since it offers no additional functionality;
# this would mean the model intercept would default to CT, likely.
# beta0 ~ dnorm(0, sd = 0.8)
# Looping over the elements of betaTrt and betaYear
for(k in 1:3) {
betaTrt[k] ~ dnorm(0, sd = 1)
}
for(k in 1:maxYear) {
betaYear[k] ~ dnorm(0, sd = 1)
}
# Random effects
# Gelman (2006) recommends the uniform prior on the sd scale not the precision scale for random effects:
# E.g., u_yi[j] ~ dnorm(0, sd = tau_yi) NOT u_yi[j] ~ dnorm(0, tau_yi)
# yi
for(j in 1:nyi) {
u_yi[j] ~ dnorm(0, sd = tau_yi)
}
# block
for(j in 1:nblock) {
u_block[j] ~ dnorm(0, sd = tau_block)
}
# id
for(j in 1:nid) {
u_id[j] ~ dnorm(0, sd = tau_id)
}
tau_yi ~ dunif(0, 1)
tau_block ~ dunif(0, 1)
tau_id ~ dunif(0, 1)
sigma ~ dunif(0, 1) # prior for variance components based on Gelman (2006);
# reduced model
for(i in 1:n) {
y[i] ~ dnorm(
betaTrt[trt[i]] +
betaYear[year[i]] +
u_yi[yi[i]] +
u_block[block[i]] +
u_id[id[i]],
sd = sigma
)
}
# Other models to consider, just commented out for reference:
# 'full model'
# for(i in 1:n) {
#   tss[i] ~ dnorm(beta0 + betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
# 'no-intercept/B0 model'
# for(i in 1:n) {
#   y[i] ~ dnorm(betaTrt[trt[i]] + betaYear[year[i]] +
#                    u_yi[yi[i]] + u_block[block[i]] + u_id[id[i]], sd = sigma)
# }
})
constants <- list(
n = nrow(tss_df),
nyi = length(unique(tss_df$yi)),
nblock = length(unique(tss_df$block)),
nid = length(unique(tss_df$id)),
maxYear = length(unique(tss_df$year)),
trt = tss_df$trt,
yi = tss_df$yi,
id = tss_df$id,
year = tss_df$year,
block = tss_df$block
)
data <- list(
y = tss_df$analyte_ctr
)
inits <- list(
# let's use the results from our estimation function here to guess sv's
#beta0 = mean(tss_df$tss),
betaTrt = rep(0, 3), # Initial values for three levels of 'trt'
betaYear = rep(0, constants$maxYear),
sigma = sv$max_sd[6], # using std. dev. of analyte_ctr from sv tibble
tau_yi = 1,
tau_block = 1,
tau_id = 1,
u_yi = rep(0, constants$nyi),
u_block = rep(0, constants$nblock),
u_id = rep(0, constants$nid)
)
TSSmodel <- nimbleModel(
code,
constants = constants,
data = data,
inits = inits
)
# Step 2: Build the MCMC
TSSmcmc <- buildMCMC(TSSmodel, enableWAIC = TRUE)
# Step 4: Run the MCMC
time_baseline <- system.time(
TSSresults <- runMCMC(TSSmcmc,
niter=11000,
nburnin=1000, #1000
WAIC=TRUE,
nchains=1)
)
